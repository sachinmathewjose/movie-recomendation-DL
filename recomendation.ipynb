{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recomendation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sachinmathewjose/movie-recomendation-DL/blob/master/recomendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr81hj-s5qzj",
        "colab_type": "code",
        "outputId": "0c124fbb-74ff-43dd-c467-f634cc07cf33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RovYwkxx6ng6",
        "colab_type": "code",
        "outputId": "6a968125-03ad-443f-a928-3fd25c92384d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "#run this in the first time\n",
        "!mkdir logs\n",
        "!cp -r '/content/drive/My Drive/colab/recomendation/datset/.' '/content/'\n",
        "!tar -xvf nf_prize_dataset.tar.gz\n",
        "!mkdir data\n",
        "!tar -C /content/data -xf download/training_set.tar\n",
        "!rm -r download\n",
        "!mkdir output\n",
        "!mkdir netflix_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "download/\n",
            "download/rmse.pl\n",
            "download/README\n",
            "download/qualifying.txt\n",
            "download/probe.txt\n",
            "download/movie_titles.txt\n",
            "download/training_set.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBwwB1khrspN",
        "colab_type": "text"
      },
      "source": [
        "###Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BJIYTZb-5YI",
        "colab_type": "code",
        "outputId": "59304907-83b2-40a4-a259-323051bdfa14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from os import listdir, path, makedirs\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import csv\n",
        "import keras # imports keras and tensorflow as backend\n",
        "import matplotlib.pyplot as plt # imports matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import os\n",
        "import time\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import optimizers\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRUJ6cXWAYnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_stats(data):\n",
        "  total_ratings = 0\n",
        "  print(\"STATS\")\n",
        "  for user in data:\n",
        "    total_ratings += len(data[user])\n",
        "  print(\"Total Ratings: {}\".format(total_ratings))\n",
        "  print(\"Total User count: {}\".format(len(data.keys())))\n",
        "  \n",
        "  \n",
        "def save_data_to_file(data, filename):\n",
        "  with open(filename, 'w') as out:\n",
        "    for userId in data:\n",
        "      for record in data[userId]:\n",
        "        out.write(\"{}\\t{}\\t{}\\n\".format(userId, record[0], record[1]))\n",
        "\n",
        "def create_NETFLIX_data_timesplit(all_data,\n",
        "                                  train_min,\n",
        "                                  train_max,\n",
        "                                  test_min,\n",
        "                                  test_max):\n",
        "  \"\"\"\n",
        "  Creates time-based split of NETFLIX data into train, and (validation, test)\n",
        "  :param all_data:\n",
        "  :param train_min:\n",
        "  :param train_max:\n",
        "  :param test_min:\n",
        "  :param test_max:\n",
        "  :return:\n",
        "  \"\"\"\n",
        "  train_min_ts = time.mktime(datetime.datetime.strptime(train_min,\"%Y-%m-%d\").timetuple())\n",
        "  train_max_ts = time.mktime(datetime.datetime.strptime(train_max, \"%Y-%m-%d\").timetuple())\n",
        "  test_min_ts = time.mktime(datetime.datetime.strptime(test_min, \"%Y-%m-%d\").timetuple())\n",
        "  test_max_ts = time.mktime(datetime.datetime.strptime(test_max, \"%Y-%m-%d\").timetuple())\n",
        "\n",
        "  training_data = dict()\n",
        "  validation_data = dict()\n",
        "  test_data = dict()\n",
        "\n",
        "  train_set_items = set()\n",
        "\n",
        "  for userId, userRatings in all_data.items():\n",
        "    time_sorted_ratings = sorted(userRatings, key=lambda x: x[2])  # sort by timestamp\n",
        "    for rating_item in time_sorted_ratings:\n",
        "      if rating_item[2] >= train_min_ts and rating_item[2] <= train_max_ts:\n",
        "        if not userId in training_data:\n",
        "          training_data[userId] = []\n",
        "        training_data[userId].append(rating_item)\n",
        "        train_set_items.add(rating_item[0]) # keep track of items from training set\n",
        "      elif rating_item[2] >= test_min_ts and rating_item[2] <= test_max_ts:\n",
        "        if not userId in training_data: # only include users seen in the training set\n",
        "          continue\n",
        "        p = random.random()\n",
        "        if p <=0.5:\n",
        "          if not userId in validation_data:\n",
        "            validation_data[userId] = []\n",
        "          validation_data[userId].append(rating_item)\n",
        "        else:\n",
        "          if not userId in test_data:\n",
        "            test_data[userId] = []\n",
        "          test_data[userId].append(rating_item)\n",
        "\n",
        "  # remove items not not seen in training set\n",
        "  for userId, userRatings in test_data.items():\n",
        "    test_data[userId] = [rating for rating in userRatings if rating[0] in train_set_items]\n",
        "  for userId, userRatings in validation_data.items():\n",
        "    validation_data[userId] = [rating for rating in userRatings if rating[0] in train_set_items]\n",
        "\n",
        "  return training_data, validation_data, test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v1UDViYZKlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "user2id_map = dict()\n",
        "item2id_map = dict()\n",
        "userId = 0\n",
        "itemId = 0\n",
        "all_data = dict()\n",
        "\n",
        "folder = 'data/training_set/'\n",
        "out_folder = 'netflix_data'\n",
        "# create necessary folders:\n",
        "for output_dir in [(out_folder + f) for f in [\n",
        "  \"/N6M_TRAIN\", \"/N6M_VALID\", \"/N6M_TEST\"]]:\n",
        "  makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "text_files = [path.join(folder, f)\n",
        "              for f in listdir(folder)\n",
        "              if path.isfile(path.join(folder, f)) and ('.txt' in f)]\n",
        "i = 0\n",
        "for text_file in text_files:\n",
        "  i = i+1\n",
        "  if i>11000:\n",
        "    with open('netflix_data/dict.csv', 'w') as csv_file:\n",
        "      writer = csv.writer(csv_file)\n",
        "      for key, value in all_data.items():\n",
        "        writer.writerow([key, value], delimiter=':')\n",
        "    all_data.clear()\n",
        "  with open(text_file, 'r') as f:\n",
        "    print(\"Processing: {}\".format(text_file))\n",
        "    lines = f.readlines()\n",
        "    item = int(lines[0][:-2]) # remove newline and :\n",
        "    if not item in item2id_map:\n",
        "      item2id_map[item] = itemId\n",
        "      itemId += 1\n",
        "\n",
        "    for rating in lines[1:]:\n",
        "      parts = rating.strip().split(\",\")\n",
        "      user = int(parts[0])\n",
        "      if not user in user2id_map:\n",
        "        user2id_map[user] = userId\n",
        "        userId += 1\n",
        "      rating = float(parts[1])\n",
        "      ts = int(time.mktime(datetime.datetime.strptime(parts[2],\"%Y-%m-%d\").timetuple()))\n",
        "      if user2id_map[user] not in all_data:\n",
        "        all_data[user2id_map[user]] = []\n",
        "      all_data[user2id_map[user]].append((item2id_map[item], rating, ts))\n",
        "\n",
        "with open('netflix_data/dict2.csv', 'w') as csv_file:\n",
        "  writer = csv.writer(csv_file)\n",
        "  for key, value in all_data.items():\n",
        "    writer.writerow([key, value])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BFlR40p0Gld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(n6m_train, n6m_valid, n6m_test) = create_NETFLIX_data_timesplit(all_data,\n",
        "                                                                 \"2005-06-01\",\n",
        "                                                                 \"2005-11-30\",\n",
        "                                                                 \"2005-12-01\",\n",
        "                                                                 \"2005-12-31\")\n",
        "print(\"Netflix 6m train\")\n",
        "print_stats(n6m_train)\n",
        "save_data_to_file(n6m_train, out_folder+\"/N6M_TRAIN/n6m.train.txt\")\n",
        "print(\"Netflix 6m valid\")\n",
        "print_stats(n6m_valid)\n",
        "save_data_to_file(n6m_valid, out_folder + \"/N6M_VALID/n6m.valid.txt\")\n",
        "print(\"Netflix 6m test\")\n",
        "print_stats(n6m_test)\n",
        "save_data_to_file(n6m_test, out_folder + \"/N6M_TEST/n6m.test.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwRPCvMRresk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r netflix_data '/content/drive/My Drive/colab/recomendation/'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4scXCKQrxCLL",
        "colab_type": "text"
      },
      "source": [
        "###Now the data is available in drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNDeXf8SxBNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r '/content/drive/My Drive/colab/recomendation/netflix_data' ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_aZCS0h7Rwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NAME = \"DeepRecommender-DR-BaselineLR-{}\".format(int(time.time()))\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='./logs/{}'.format(NAME))\n",
        "DATA_DIR = 'netflix_data'\n",
        "nf_6m_train = os.path.join(DATA_DIR, 'N6M_TRAIN', 'n6m.train.txt')\n",
        "nf_6m_valid = os.path.join(DATA_DIR, 'N6M_VALID', 'n6m.valid.txt')\n",
        "nf_6m_test = os.path.join(DATA_DIR, 'N6M_TEST', 'n6m.test.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yaba9CM7tI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(nf_3m_train, names=['CustomerID','MovieID','Rating'], sep='\\t')\n",
        "print(df_train.shape)\n",
        "df_train.head()\n",
        "df_valid = pd.read_csv(nf_3m_valid, names=['CustomerID','MovieID','Rating'], sep='\\t')\n",
        "print(df_valid.shape)\n",
        "df_valid.head()\n",
        "df_test = pd.read_csv(nf_3m_test, names=['CustomerID','MovieID','Rating'], sep='\\t')\n",
        "print(df_test.shape)\n",
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYwgeW819oBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "customer_map = df_train.CustomerID.unique()\n",
        "customer_map.sort()\n",
        "customer_map = customer_map[0:17550]\n",
        "#user_map\n",
        "num_users = len(customer_map)\n",
        "customer_map[-1]\n",
        "\n",
        "movie_map = df_train.MovieID.unique()\n",
        "movie_map.sort()\n",
        "movie_map = movie_map[0:1000]\n",
        "#movie_map\n",
        "num_movies = len(movie_map)\n",
        "movie_map[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DFN6zIL90mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run this only once\n",
        "file = open('matrix_train.csv','w')\n",
        "def temp(i):\n",
        "    return np.where(movie_map == i)[0][0]\n",
        "\n",
        "for id_user in customer_map:\n",
        "    id_movie = df_train.iloc[:,1][(df_train.iloc[:,0]==id_user) & (df_train.iloc[:,1]<=1000)]\n",
        "    id_movie = id_movie.apply(temp)\n",
        "    id_rating=df_train.iloc[:,2][(df_train.iloc[:,0]==id_user) & (df_train.iloc[:,1]<=1000)]\n",
        "    ratings=np.zeros(num_movies, dtype=np.uint32)\n",
        "    ratings[id_movie-1]=id_rating\n",
        "    if sum(ratings)==0:\n",
        "        continue\n",
        "    ratings=pd.DataFrame(ratings.reshape(-1, len(ratings)))\n",
        "    file.write(ratings.to_csv(index=False, header=False))\n",
        "    del id_movie\n",
        "    del id_rating\n",
        "    del ratings\n",
        "\n",
        "\n",
        "file.close()\n",
        "\n",
        "\n",
        "X = pd.read_csv('matrix_train.csv', header=None)\n",
        "print(X.shape)\n",
        "X.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXMtBHTy-kbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "customer_map = df_valid.CustomerID.unique()\n",
        "customer_map.sort()\n",
        "customer_map = customer_map[:7020]\n",
        "num_users = len(customer_map)\n",
        "customer_map[-1]\n",
        "\n",
        "movie_map = df_valid.MovieID.unique()\n",
        "movie_map.sort()\n",
        "movie_map = movie_map[:895]\n",
        "#movie_map\n",
        "num_movies = len(movie_map)\n",
        "movie_map[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3wZUOjy_Iby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open('matrix_valid.csv','w')\n",
        "\n",
        "def temp(i):\n",
        "    return np.where(movie_map == i)[0][0]\n",
        "\n",
        "for id_user in customer_map:\n",
        "    id_movie = df_valid.iloc[:,1][(df_valid.iloc[:,0]==id_user) & (df_valid.iloc[:,1]<=1000)]\n",
        "    id_movie = id_movie.apply(temp)\n",
        "    id_rating=df_valid.iloc[:,2][(df_valid.iloc[:,0]==id_user) & (df_valid.iloc[:,1]<=1000)]\n",
        "    ratings=np.zeros(1000, dtype=np.uint32)\n",
        "    ratings[id_movie-1]=id_rating\n",
        "    if sum(ratings)==0:\n",
        "        continue\n",
        "    ratings=pd.DataFrame(ratings.reshape(-1, len(ratings)))\n",
        "    file.write(ratings.to_csv(index=False, header=False))\n",
        "    del id_movie\n",
        "    del id_rating\n",
        "    del ratings\n",
        "\n",
        "file.close()\n",
        "\n",
        "\n",
        "X_valid = pd.read_csv('matrix_valid.csv', header=None)\n",
        "print(X_valid.shape)\n",
        "X_valid.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R6wTKo7_1Bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "customer_map = df_test.CustomerID.unique()\n",
        "customer_map.sort()\n",
        "customer_map = customer_map[:7020]\n",
        "num_users = len(customer_map)\n",
        "customer_map[-1]\n",
        "\n",
        "movie_map = df_test.MovieID.unique()\n",
        "movie_map.sort()\n",
        "movie_map = movie_map[:901]\n",
        "#movie_map\n",
        "num_movies = len(movie_map)\n",
        "movie_map[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8IGWSjb_8EJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open('matrix_test.csv','w')\n",
        "\n",
        "def temp(i):\n",
        "    return np.where(movie_map == i)[0][0]\n",
        "\n",
        "for id_user in customer_map:\n",
        "    id_movie = df_test.iloc[:,1][(df_test.iloc[:,0]==id_user) & (df_test.iloc[:,1]<=1000)]\n",
        "    id_movie = id_movie.apply(temp)\n",
        "    id_rating=df_test.iloc[:,2][(df_test.iloc[:,0]==id_user) & (df_test.iloc[:,1]<=1000)]\n",
        "    ratings=np.zeros(1000, dtype=np.uint32)\n",
        "    ratings[id_movie-1]=id_rating\n",
        "    if sum(ratings)==0:\n",
        "        continue\n",
        "    ratings=pd.DataFrame(ratings.reshape(-1, len(ratings)))\n",
        "    file.write(ratings.to_csv(index=False, header=False))\n",
        "    del id_movie\n",
        "    del id_rating\n",
        "    del ratings\n",
        "\n",
        "file.close()\n",
        "\n",
        "X_test = pd.read_csv('matrix_test.csv', header=None)\n",
        "print(X_test.shape)\n",
        "X_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkUG1QFvABpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rmse(y_true, y_pred):\n",
        "    mask_true = K.cast(K.not_equal(y_true, 0), K.floatx())\n",
        "    masked_squared_error = mask_true * K.square((y_true - y_pred))\n",
        "    # in case mask_true is 0 everywhere, the error would be nan, therefore divide by at least 1\n",
        "    # this doesn't change anything as where sum(mask_true)==0, sum(masked_squared_error)==0 as well\n",
        "    masked_mse = K.sum(masked_squared_error, axis=-1) / K.maximum(K.sum(mask_true, axis=-1), 1)\n",
        "    return K.sqrt(masked_mse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9k-T7xSBzoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(28, input_dim = X.shape[1], activation='selu'))\n",
        "model.add(Dense(56, activation='selu'))\n",
        "model.add(Dense(56, activation='selu'))\n",
        "model.add(Dropout(0.65))\n",
        "model.add(Dense(56, activation='selu'))\n",
        "model.add(Dense(28, activation='selu'))\n",
        "model.add(Dense(X.shape[1], activation='selu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBV0NwhNB9mF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = optimizers.SGD(lr=0.005, momentum=0.9)\n",
        "model.compile(loss=rmse, optimizer=sgd)\n",
        "\n",
        "model.fit(X, X, batch_size=128, epochs=100, validation_data=(X_valid, X_valid), callbacks=[tensorboard])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acDZ0vLDCBgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss = model.evaluate(X_test, X_test)\n",
        "test_loss"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}